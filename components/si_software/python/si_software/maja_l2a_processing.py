#!/usr/bin/env python3
# -*- coding: utf-8 -*-


from si_common.common_functions import *
from si_common.follow_process import execute_commands, dump_execution_dict_to_directory
from si_utils.compress_geotiff import replicate_directory_with_compressed_tiffs
from si_geometry.geometry_functions import *
from si_geometry.get_valid_data_convex_hull import get_valid_data_convex_hull
from si_software.maja_slim import maja_slim


############################    


def extract_l2a_metadata_from_l2a(l2a_path, l2a_metadata_output_path):
    os.makedirs(l2a_metadata_output_path)
    xml_file = os.path.basename(l2a_path) + '_MTD_ALL.xml'
    shutil.copy(os.path.join(l2a_path, xml_file), os.path.join(l2a_metadata_output_path, xml_file))
    shutil.copytree(os.path.join(l2a_path, 'DATA'), os.path.join(l2a_metadata_output_path, 'DATA'))
    

def clean_l2a_keep_metadata(l2a_path):
    os.system('rm -f %s/*.tif'%l2a_path)
    os.system('rm -f %s/*.TIF'%l2a_path)
    os.system('rm -f %s/*.jpg'%l2a_path)
    os.system('rm -Rf %s/MASKS'%l2a_path)

def maja_l2a_final_editing(l2a_input_dir, l2a_output_dir):
    replicate_directory_with_compressed_tiffs(l2a_input_dir, output_fol=l2a_output_dir, tiled=True, compress='deflate', zlevel=4, predictor=1)
    

def find_and_check_l2a_from_maja_output(maja_out_dir, remove_sre_bands=True):
    
    files_expected_main_folder = set(['ATB_R%s.tif'%ii for ii in [1,2]] + \
        ['%s_B%s.tif'%(tag, ii) for ii in [2,3,4,5,6,7,8,'8A',11,12] for tag in ['SRE', 'FRE']])
        
    l2a_file = ['%s/%s'%(maja_out_dir, el) for el in os.listdir(maja_out_dir) if os.path.isdir('%s/%s'%(maja_out_dir, el)) and 'SENTINEL' in el]
    if len(l2a_file) == 0:
        return None, 'no file found'
    if len(l2a_file) > 1:
        return None, 'multiple files found'
        
    #L2a file found and unique
    l2a_file = l2a_file[0]
    
    listdir_main = os.listdir(l2a_file)
    sufixes_main = set(['_'.join(el.split('_')[-2:]) for el in listdir_main if not os.path.isdir('%s/%s'%(l2a_file, el))])
    
    try:
        #first check if files necessary to use this L2A as a MAJA run source in nominal mode are present, otherwise return 'maja_source_incomplete' status
        if not 'DATA' in listdir_main:
            return l2a_file, 'DATA folder missing in L2A file %s'%l2a_file
        if not 'MTD_ALL.xml' in sufixes_main:
            return l2a_file, 'MTD_ALL.xml file missing in L2A file %s'%l2a_file
        #check within DATA folder
        file_list_data = os.listdir('%s/DATA'%l2a_file)
        sufixes_data = set(['_'.join(el.split('_')[-2:]) for el in file_list_data])
        if len(set(['JPI_ALL.xml', 'PVD_ALL']) - sufixes_data) > 0:
            return l2a_file, 'Elements missing from DATA folder'
        subdata = [el for el in file_list_data if el.split('_')[-1] == 'ALL' and os.path.isdir('%s/DATA/%s'%(l2a_file, el))]
        if len(subdata) == 0:
            return l2a_file, 'PVD_ALL folder within DATA folder missing from L2A file %s'%l2a_file
        if len(subdata) > 1:
            return l2a_file, 'Multiple PVD_ALL folders within DATA folder in L2A file %s'%l2a_file
        subdata = '%s/DATA/%s'%(l2a_file, subdata[0])
        subdata_list = os.listdir(subdata)
        if (len(subdata_list) != 19) or ('LTC' not in subdata_list):
            return l2a_file, 'Files missing from PVD_ALL folder within DATA folder in L2A file %s'%l2a_file
        if len(os.listdir('%s/LTC'%subdata)) == 0:
            return l2a_file, 'Files missing from LTD folder in PVD_ALL folder within DATA folder in L2A file %s'%l2a_file
    except:
        return l2a_file, 'Failed to analyse MAJA source files in L2A file %s'%l2a_file
    
    
    try:
        #check other files/folders to see if L2A product is complete
        if not 'MASKS' in listdir_main:
            return l2a_file, 'MASKS folder missing in L2A file %s'%l2a_file
        if len(files_expected_main_folder - sufixes_main) > 0:
            return l2a_file, 'Files missing from L2A file %s :\n%s\n'%(l2a_file, '\n'.join(sorted(list(files_expected_main_folder - sufixes_main))))
            
        #L2a file is complete !
        #move processing files generated by MAJA with L2A file within an exec_files folder within L2A file => gives info about quality
        os.system('mkdir -p %s/exec_files'%l2a_file)
        for el in os.listdir(maja_out_dir):
            if el != l2a_file.split('/')[-1]:
                shutil.move('%s/%s'%(maja_out_dir, el), '%s/exec_files/%s'%(l2a_file, el))
        
    except:
        return l2a_file, 'incomplete'
        
        
    #SRE bands are unused by LIS and ICE so they can be removed => implemented mostly to save disk space on CNES cluster (divide by ~2 for L2A storage)
    if remove_sre_bands:
        maja_slim(l2a_file, metadata_version=None, remove_r2=False, verbose=0)
        
    return l2a_file, 'complete'



    
    
def update_product_information_from_l2a_file(product_information, l2a_path, temp_dir=None):
    """After MAJA execution, product information can be completed => to be used to fill product information within product XML files"""
    
    #fill information from l2a_path
    mission_fullname = l2a_path.split('/')[-1].split('_')[0]
    if mission_fullname == 'SENTINEL2A':
        product_information['mission'] = 'S2A'
    elif mission_fullname == 'SENTINEL2B':
        product_information['mission'] = 'S2B'
    else:
        raise RuntimeArgError('mission %s recovered from L2A file unknown'%mission_fullname)
        
    #parse L2A xml file
    l2a_xml_path = os.path.join(l2a_path, os.path.basename(l2a_path) + '_MTD_ALL.xml')
    with open(l2a_xml_path) as ds:
        lines = ds.readlines()
    product_information['measurement_date'] = None
    product_information['cloud_cover_percent'] = None
    for line in lines:
        if '<QUALITY_INDEX name="CloudPercent">' in line:
            if product_information['cloud_cover_percent'] is not None:
                raise RuntimeArgError('found <QUALITY_INDEX name="CloudPercent"> multiple times in L2A xml files')
            product_information['cloud_cover_percent'] = float(line.split('</')[0].split('>')[-1])
        elif '<ACQUISITION_DATE>' in line:
            if product_information['measurement_date'] is not None:
                continue
            product_information['measurement_date'] = datetime.strptime(line.split('</')[0].split('>')[-1], '%Y-%m-%dT%H:%M:%S.%fZ')
    assert product_information['measurement_date'] is not None
    assert product_information['cloud_cover_percent'] is not None
    assert abs(product_information['measurement_date'] - datetime.strptime(l2a_path.split('/')[-1].split('_')[1] + '000', '%Y%m%d-%H%M%S-%f')) < timedelta(0,1), \
        'measurement date in L2A xml file does not match date in L2A file name'
        
    #compute shape around data
    product_information['wekeo_geom'] = get_valid_data_convex_hull(os.path.join(l2a_path, 'MASKS', os.path.basename(l2a_path) + '_EDG_R2.tif'), \
        valid_values=[0], proj_out='EPSG:4326', temp_dir=temp_dir).wkt
        
    product_information['tile_name'] = l2a_path.split('/')[-1].split('_')[3][1:]
    assert product_information['product_mode_overide'] in set([0,1]), 'product_mode_overide must be 0 or 1'
    product_information['tag'] = '%s_%s_%s_%s_%d'%(product_information['measurement_date'].strftime('%Y%m%dT%H%M%S'), product_information['mission'], 'T' + product_information['tile_name'], \
        product_information['general_info']['product_version'], product_information['product_mode_overide'])
    
    #fill template information (used to fill FSC, RLIE, PSL and ARLIE templates)
    product_information['template'] = dict()
    #copy information filled by CoSIMS team in the general_info.yaml file
    for key in ['helpdesk_email', 'product_version', 'pum_url', 'dias_url', 'dias_portal_name', 'report_date']:
        product_information['template'][key.upper()] = product_information['general_info'][key]
    for el in ['FSC', 'RLIE']:
        product_information['template']['%s_PRODUCT_ID'%el] = '%s_%s'%(el, product_information['tag'])
    product_information['template']['VALIDATION_REPORT_FILENAME'] = 'hrsi-snow-qar'
    product_information['template']['PRODUCTION_DATE'] = product_information['production_date'].strftime('%Y-%m-%dT%H:%M:%S.%f%Z')
    product_information['template']['EDITION_DATE'] = product_information['production_date'].strftime('%Y-%m-%dT%H:%M:%S.%f%Z')
    product_information['template']['ACQUISITION_START'] = product_information['measurement_date'].strftime('%Y-%m-%dT%H:%M:%S.%f%Z')
    product_information['template']['ACQUISITION_STOP'] = product_information['measurement_date'].strftime('%Y-%m-%dT%H:%M:%S.%f%Z')
    
    #get lonlat border information from the R1.tif file in L2A data
    file_get_coords = ['%s/%s'%(l2a_path, el) for el in os.listdir(l2a_path) if 'R1.tif' in el]
    if len(file_get_coords) == 0:
        raise Exception('Could not find L2A R1.tif file to get tile coordinates')
    lonlat_minmax_dict = RasterPerimeter(file_get_coords[0]).get_lonlat_minmax()
    product_information['template']['WB_lon'] = '%s'%lonlat_minmax_dict['lonmin']
    product_information['template']['EB_lon'] = '%s'%lonlat_minmax_dict['lonmax']
    product_information['template']['SB_lat'] = '%s'%lonlat_minmax_dict['latmin']
    product_information['template']['NB_lat'] = '%s'%lonlat_minmax_dict['latmax']
            
    return product_information
    
    
def copy_static_maja_files_modify_max_cloud_coverage(static_parameter_files_dir, maja_in_fol, max_cloud_cover_acceptable_percent=100., copy_all=False):    
    
    if max_cloud_cover_acceptable_percent == 100.:
        max_cloud_cover_acceptable_percent = 101.
        
    count_lines_adjusted_cloud = 0
    count_lines_adjusted_cirrus = 0
    for filename in os.listdir(static_parameter_files_dir):
        filepath_src = os.path.join(static_parameter_files_dir, filename)
        filepath_target = os.path.join(maja_in_fol, filename)
        if filename.split('.')[-1] == 'EEF':
            with open(filepath_src) as ds:
                lines = ds.readlines()
            for ii in range(len(lines)):
                if '<Max_Cloud_Percentage>' in lines[ii]:
                    old_value = lines[ii].split('<Max_Cloud_Percentage>')[-1].split('</Max_Cloud_Percentage>')[0]
                    lines[ii] = lines[ii].replace(old_value, '%s'%max_cloud_cover_acceptable_percent)
                    count_lines_adjusted_cloud += 1
                if '<Cirrus_Correction_Option>' in lines[ii]:
                    old_value = lines[ii].split('<Cirrus_Correction_Option>')[-1].split('</Cirrus_Correction_Option>')[0]
                    lines[ii] = lines[ii].replace(old_value, 'false')
                    count_lines_adjusted_cirrus += 1
            with open(filepath_target, mode='w') as ds:
                ds.write('\n'.join(lines))
        else:
            if copy_all:
                copy_original(filepath_src, filepath_target)
            else:
                create_link(filepath_src, filepath_target)
                
    assert count_lines_adjusted_cloud == 4, 'there should be 4 files with <Max_Cloud_Percentage>...</Max_Cloud_Percentage> lines in which to set max_cloud_cover_acceptable_percent parameter value'
    assert count_lines_adjusted_cirrus == 4, 'there should be 4 files with <Cirrus_Correction_Option>...</Cirrus_Correction_Option> lines in which to set value to false'
    




def make_maja_script(cmd, cmd_file):
    
    #write script to file and make it executable
    with open(cmd_file, mode='w') as ds:
        ds.write(cmd)
    os.system('chmod u+x %s'%cmd_file)
    
    return ['sh', '%s'%cmd_file]

    
def maja_l2a_processing(main_info):
    
    main_info.update_processing_status(new_value='maja_preprocessing')
    main_info.logger_info('')
    main_info.logger_info('')
    main_info.logger_info('##########################################################################################')
    main_info.logger_info('MAJA')
    main_info.logger_info('')
    main_info.logger_info('MAJA preprocessing...')
    
    dico = main_info.input_parameters

    ######################
    #prepare inputs
    maja_temp_dir = os.path.join(main_info.main_temp_dir, 'maja')
    for fol in ['in', 'out']:
        os.makedirs(os.path.join(maja_temp_dir, fol), exist_ok=True)
        
    #copy static files to MAJA in dir but modify Max_Cloud_Percentage in .EEF files to set value from dico['maja']['max_cloud_cover_acceptable_percent']
    copy_static_maja_files_modify_max_cloud_coverage(dico['maja']['static_parameter_files_dir'], os.path.join(maja_temp_dir, 'in'), \
        max_cloud_cover_acceptable_percent=dico['maja']['max_cloud_cover_acceptable_percent'], copy_all=dico['copy_input_files_to_temp_dir'])
        
    if dico['copy_input_files_to_temp_dir']:
        #copy all necessary file to temp dir
        copy_original(dico['maja']['user_config_dir'], '%s/userconf'%maja_temp_dir)
        copy_all(dico['dem_dir'] + '/*', '%s/in'%maja_temp_dir)
        if isinstance(dico['maja']['l1c_file'], list):
            for el in dico['maja']['l1c_file']:
                copy_original(el, '%s/in/%s'%(maja_temp_dir, el.split('/')[-1]))
        else:
            copy_original(dico['maja']['l1c_file'], '%s/in/%s'%(maja_temp_dir, dico['maja']['l1c_file'].split('/')[-1]))
        if dico['maja']['l2a_file'] is not None:
            copy_original(dico['maja']['l2a_file'], '%s/in/%s'%(maja_temp_dir, dico['maja']['l2a_file'].split('/')[-1]))
    else:
        #create links to all necessary files
        create_link(dico['maja']['user_config_dir'], '%s/userconf'%maja_temp_dir)
        link_all(dico['dem_dir'] + '/*', '%s/in'%maja_temp_dir)
        if isinstance(dico['maja']['l1c_file'], list):
            for el in dico['maja']['l1c_file']:
                create_link(el, '%s/in/%s'%(maja_temp_dir, el.split('/')[-1]))
        else:
            create_link(dico['maja']['l1c_file'], '%s/in/%s'%(maja_temp_dir, dico['maja']['l1c_file'].split('/')[-1]))
        if dico['maja']['l2a_file'] is not None:
            create_link(dico['maja']['l2a_file'], '%s/in/%s'%(maja_temp_dir, dico['maja']['l2a_file'].split('/')[-1]))
            

            
            
    ######################
    #execute MAJA
    cmd_maja = 'unset PYTHONPATH\n'
    cmd_maja += 'maja -i {0}/in -o {0}/out -m L2{1} -ucs {0}/userconf --TileId {2} --NbThreads {3}'.format(maja_temp_dir, dico['maja']['mode'].upper(), dico['tile_name'], dico['nprocs'])
    if dico['maja']['additional_maja_options'] is not None:
        cmd_maja += ' '.join([el for el in dico['maja']['additional_maja_options'].split() if len(el) > 0])
    cmd_maja = make_maja_script(cmd_maja, os.path.join(maja_temp_dir, 'launch_maja.sh'))
    cmd_maja = {'cmd': cmd_maja, 'stdout_write_objects': [main_info.get_subtask_logger_writer(prefix='MAJA stdout')], 'stderr_write_objects': [main_info.get_subtask_logger_writer(prefix='MAJA stderr')]}
    #MAJA launch job
    main_info.logger_info('Launching MAJA:\n%s'%(' '.join(cmd_maja)))
    main_info.update_processing_status(new_value='maja_start')
    execution_dict = execute_commands({'maja': cmd_maja}, maxtime_seconds=dico['maja']['max_processing_time'], scan_dt=1, verbose=0)['maja']
    main_info.logger_info('MAJA return code: %s'%execution_dict['returncode'])


    ######################
    #MAJA postprocessing
    main_info.update_processing_status(new_value='maja_postprocessing')
    l2a_file = None
    #check MAJA success/failure
    dump_execution_dict_to_directory(execution_dict, '%s/logs/maja'%main_info.main_output_dir)
    too_many_nan = any(['The number of NoData pixel in the output L2 composite product is too high.' in line or 'ZeroDivisionError: float division by zero' in line or \
        'A spacing of 0 is not allowed: Spacing is' in line for line in execution_dict['stdout']]) or \
        any(['The number of NoData pixel in the output L2 composite product is too high.' in line or 'ZeroDivisionError: float division by zero' in line or \
        'A spacing of 0 is not allowed: Spacing is' in line for line in execution_dict['stderr']])
    cloud_cover_too_high = any(['The number of cloudy pixel is too high. The level2 algorithm processing is stopped!' in line for line in execution_dict['stdout']]) or \
        any(['The number of cloudy pixel is too high. The level2 algorithm processing is stopped!' in line for line in execution_dict['stderr']])
    no_minilut_error = any(['[E]' in line and 'no miniLUT has been generated for this angle zone' in line for line in execution_dict['stdout']]) or \
        any(['[E]' in line and 'no miniLUT has been generated for this angle zone' in line for line in execution_dict['stderr']])
    no_detect_l1c = any(['[E]' in line and 'Impossible to detect a L1 product' in line for line in execution_dict['stdout']]) or \
        any(['[E]' in line and 'Impossible to detect a L1 product' in line for line in execution_dict['stderr']])
    zenithal_angle_error = any(['[E]' in line and 'The number of detector for viewing zenithal angles and viewing azimuthal angles is different or null !' in line for line in execution_dict['stdout']]) or \
        any(['[E]' in line and 'The number of detector for viewing zenithal angles and viewing azimuthal angles is different or null !' in line for line in execution_dict['stderr']])
    missing_band_error = any(['[E]' in line and 'Could not create IO object for file' in line for line in execution_dict['stdout']]) or \
        any(['[E]' in line and 'Could not create IO object for file' in line for line in execution_dict['stderr']])
    l1c_parsing_error = any(['[E]' in line and 'Parsed with errors' in line for line in execution_dict['stdout']]) or \
        any(['[E]' in line and 'Parsed with errors' in line for line in execution_dict['stderr']])
    if too_many_nan:
        main_info.update_processing_status(new_value='maja_too_many_nan')
        raise CodedException('MAJA : Too many NAN !', exitcode=fsc_rlie_exitcodes.maja_too_many_nan)
    elif cloud_cover_too_high:
        main_info.update_processing_status(new_value='maja_cloud_cover_too_high')
        raise CodedException('MAJA : Too cloudy !', exitcode=fsc_rlie_exitcodes.maja_too_cloudy)
    elif no_minilut_error:
        main_info.update_processing_status(new_value='maja_no_minilut_error')
        raise CodedException('MAJA : No minilut error !', exitcode=fsc_rlie_exitcodes.no_minilut_error)
    elif no_detect_l1c:
        main_info.update_processing_status(new_value='maja_no_detect_l1c')
        raise CodedException('MAJA : No L1C detected in input directory !', exitcode=fsc_rlie_exitcodes.no_detect_l1c)
    elif zenithal_angle_error:
        main_info.update_processing_status(new_value='maja_zenithal_angle_error')
        raise CodedException('MAJA : Zenithal angle error !', exitcode=fsc_rlie_exitcodes.zenithal_angle_error)
    elif missing_band_error:
        main_info.update_processing_status(new_value='maja_missing_band_error')
        raise CodedException('MAJA : Missing L1C band error !', exitcode=fsc_rlie_exitcodes.missing_band_error)
    elif l1c_parsing_error:
        main_info.update_processing_status(new_value='maja_l1c_parsing_error')
        raise CodedException('MAJA : L1C parsing error !', exitcode=fsc_rlie_exitcodes.l1c_parsing_error)
    elif execution_dict['returncode'] == 0:
        #check MAJA L2A output
        l2a_file, status_l2a_file = find_and_check_l2a_from_maja_output('%s/out'%maja_temp_dir, remove_sre_bands=dico['maja']['remove_sre_bands'])
        if status_l2a_file != 'complete':
            main_info.logger_info(status_l2a_file)
            main_info.update_processing_status(new_value='maja_failed')
            raise Exception('MAJA processing did not generate any products: %s'%status_l2a_file)
        else:
            #saving L2A file
            maja_l2a_final_editing(l2a_file, '%s/data/%s'%(main_info.main_output_dir, l2a_file.split('/')[-1]))
            main_info.update_product_dict(new_product_keyval_tuple=('l2a', l2a_file.split('/')[-1]))
            main_info.logger_info('MAJA processing successful, completed in %s seconds'%execution_dict['execution_time'])
            main_info.update_product_information_from_maja_output(l2a_file)
    elif execution_dict['exceeded_time']:
        main_info.update_processing_status(new_value='maja_expired')
        raise CodedException('MAJA calculation exceeded %s seconds => terminating csi_si_software'%dico['exec_time_max'], exitcode=exitcodes.subprocess_user_defined_timeout)
    else:
        main_info.update_processing_status(new_value='maja_failed')
        execution_dict['stderr'] = [el for el in execution_dict['stdout'] if '[E]' in el] + execution_dict['stderr']
        raise CodedException('MAJA returned with error %s after %s seconds => terminating csi_si_software\n%s\n'%(execution_dict['returncode'], \
            execution_dict['execution_time'], '\n'.join(execution_dict['stderr'])), exitcode=fsc_rlie_exitcodes.maja_unknown_error)
            



    
